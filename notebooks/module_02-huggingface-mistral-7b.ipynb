{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd517d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "import niquests\n",
    "import orjson\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "torch.random.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb6167",
   "metadata": {},
   "source": [
    "## MinSearch (Toy Search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef45dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = \"https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json\"\n",
    "docs_response = niquests.get(docs_url)\n",
    "assert docs_response.content is not None\n",
    "documents_raw = orjson.loads(docs_response.content)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course[\"course\"]\n",
    "\n",
    "    for doc in course[\"documents\"]:\n",
    "        doc[\"course\"] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"], keyword_fields=[\"course\"]\n",
    ")\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bebed8",
   "metadata": {},
   "source": [
    "## Load HuggingFace Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4453955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\",\n",
    "    device_map=\"cuda\",\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", padding_side=\"left\"\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7fb04",
   "metadata": {},
   "source": [
    "## Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {\"question\": 3.0, \"section\": 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={\"course\": \"data-engineering-zoomcamp\"},\n",
    "        boost_dict=boost,\n",
    "        num_results=5,\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "If the CONTEXT doesn't contain the answer, output NONE\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = (\n",
    "            context\n",
    "            + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "        )\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3021a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    generation_args = {\n",
    "        \"max_new_tokens\": 500,\n",
    "        \"return_full_text\": False,\n",
    "        \"temperature\": 1.0,\n",
    "        \"do_sample\": False,\n",
    "    }\n",
    "\n",
    "    output = pipe(messages, **generation_args)\n",
    "    return output[0][\"generated_text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b528fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f440f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka:\n",
      "\n",
      "If you are using Java Kafka and need to run the producer/consumer/kstreams/etc from the terminal, navigate to the project directory and execute the following command:\n",
      "\n",
      "```bash\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "```\n",
      "\n",
      "Make sure to replace `<jar_name>` with the appropriate JAR file name from your build.\n",
      "\n",
      "If you are facing issues running Python Kafka files, consider creating a virtual environment, installing the required dependencies using `requirements.txt`, and running the files within that environment. See the detailed steps provided in the CONTEXT for managing virtual environments.\n",
      "\n",
      "If your question pertains to another Kafka use case that is not mentioned here, the CONTEXT does not have additional details. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"How do I run kafka?\"\n",
    "answer = rag(query)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec9840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
